# IoT Time Series Forecasting with LLM

This project demonstrates the use of a fine-tuned language model (LLM) for time series forecasting. The notebook evaluates the model's performance on a validation dataset and calculates key metrics.

## Files and Directories
- **scripts/evaluate_llm_forecaster.ipynb**: Jupyter Notebook for evaluating the LLM forecaster.
- **models/llm_forecaster/**: Directory containing the fine-tuned LLM model.
- **data/llm_preprocessed/val.csv**: Validation dataset used for evaluation.
- **outputs/evaluation_results.png**: PNG file containing evaluation metrics.

## Steps in the Notebook
1. **Setup**:
   - Import necessary libraries.
   - Configure the device (MPS or CPU) and define file paths.

2. **Load Fine-Tuned Model**:
   - Load the tokenizer and model from the `models/llm_forecaster/` directory.
   - Set the model to evaluation mode.

3. **Load Validation Data**:
   - Read the validation dataset (`val.csv`) and preprocess it.
   - Define a function to create input prompts for the model.

4. **Generate Predictions**:
   - Use a sliding window approach to generate predictions for the time series.
   - Handle decoding errors and store predictions and true values.

5. **Evaluate and Save Results**:
   - Calculate evaluation metrics: MSE, MAE, and SMAPE.
   - Save the metrics as a PNG file in the `outputs/` directory.

## How to Run
1. Install the required Python libraries:
   ```bash
   pip install -r requirements.txt
   ```
2. Activate the virtual environment:
   ```bash
   source venv/bin/activate
   ```
3. Open the notebook:
   ```bash
   jupyter notebook scripts/evaluate_llm_forecaster.ipynb
   ```
4. Run all cells to evaluate the model.

## Evaluation Metrics
- **Mean Squared Error (MSE)**: Measures the average squared difference between predictions and true values.
- **Mean Absolute Error (MAE)**: Measures the average absolute difference between predictions and true values.
- **Symmetric Mean Absolute Percentage Error (SMAPE)**: Measures the percentage error between predictions and true values.

## Outputs
- The evaluation results are saved as a PNG file in the `outputs/` directory:
  ```
  outputs/evaluation_results.png
  ```

## Notes
- Ensure that the fine-tuned model is available in the `models/llm_forecaster/` directory.
- Update `VAL_FILE` in the notebook if the validation dataset path changes.
