{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Autoformer: Enhancing Transformers for Time Series Forecasting\n",
    "\n",
    "Autoformer improves Transformers for time series forecasting by introducing two key innovations:\n",
    "\n",
    "1. **Decomposition of Input Series**: The input time series is decomposed into trend and seasonality components. This allows the model to focus on learning each component separately, improving its ability to capture long-term dependencies and patterns. ‚úÇÔ∏è\n",
    "\n",
    "2. **Improved Long-Term Prediction**: By learning the trend and seasonality components independently, Autoformer enhances its forecasting accuracy, especially for long-term predictions. üìà\n",
    "\n",
    "This implementation is designed to be clean, lightweight, and runnable, similar to the Informer model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a13b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 1: Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')  # Handle custom imports\n",
    "\n",
    "from models.timeseries_dataset_class import TimeSeriesDataset\n",
    "from models.transformer_model_definitions import SeriesDecomposition, AutoformerBlock, AutoformerForecast\n",
    "\n",
    "# ‚úÖ Enable GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006244dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Step 2: Load Preprocessed Splits\n",
    "train_df = pd.read_csv(\"../data/processed/etth1_train.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "val_df = pd.read_csv(\"../data/processed/etth1_val.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "test_df = pd.read_csv(\"../data/processed/etth1_test.csv\", parse_dates=[\"date\"], index_col=\"date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879f87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "target_column = \"OT\"\n",
    "window_size = 96\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1be6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Step 3: Create Datasets and Dataloaders\n",
    "train_loader = DataLoader(TimeSeriesDataset(train_df[target_column].values, window_size),\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TimeSeriesDataset(val_df[target_column].values, window_size),\n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TimeSeriesDataset(test_df[target_column].values, window_size),\n",
    "                         batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73956b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.0302\n",
      "[Epoch 2] Train Loss: 0.0007\n",
      "[Epoch 3] Train Loss: 0.0006\n",
      "[Epoch 4] Train Loss: 0.0006\n",
      "[Epoch 5] Train Loss: 0.0006\n",
      "[Epoch 6] Train Loss: 0.0006\n",
      "[Epoch 7] Train Loss: 0.0006\n",
      "[Epoch 8] Train Loss: 0.0006\n",
      "[Epoch 9] Train Loss: 0.0005\n",
      "[Epoch 10] Train Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚öôÔ∏è Step 4: Train Autoformer Model\n",
    "model = AutoformerForecast().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device).unsqueeze(1)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2730cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved\n"
     ]
    }
   ],
   "source": [
    "# üíæ Save the trained model\n",
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/checkpoints/autoformer_transformer_model.pth\")\n",
    "print(\"‚úÖ Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3ba483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Step 5: Define Evaluation Function\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return 100 * np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2baee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, dataset_df, title, file_prefix):\n",
    "    model.eval()\n",
    "    all_preds, all_trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device).unsqueeze(1)\n",
    "            pred = model(x)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_trues.append(y.cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(all_preds).flatten()\n",
    "    true_values = np.concatenate(all_trues).flatten()\n",
    "\n",
    "    # Inverse scale using original df\n",
    "    dummy_shape = (predictions.shape[0], dataset_df.shape[1])\n",
    "    predictions_full = np.zeros(dummy_shape)\n",
    "    true_values_full = np.zeros(dummy_shape)\n",
    "    predictions_full[:, -1] = predictions\n",
    "    true_values_full[:, -1] = true_values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(dataset_df)\n",
    "    predictions = scaler.inverse_transform(predictions_full)[:, -1]\n",
    "    true_values = scaler.inverse_transform(true_values_full)[:, -1]\n",
    "\n",
    "    # üí° Metrics\n",
    "    mse = mean_squared_error(true_values, predictions)\n",
    "    mae = mean_absolute_error(true_values, predictions)\n",
    "    smape_val = smape(true_values, predictions)\n",
    "\n",
    "    print(f\"üìä {title}\")\n",
    "    print(f\" - MSE   : {mse:.6f}\")\n",
    "    print(f\" - MAE   : {mae:.6f}\")\n",
    "    print(f\" - SMAPE : {smape_val:.2f}%\")\n",
    "\n",
    "    # üìà Plot\n",
    "    os.makedirs(\"../../outputs/metrics/autoformer\", exist_ok=True)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(true_values[:100], label=\"True\")\n",
    "    plt.plot(predictions[:100], label=\"Predicted\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"../../outputs/metrics/autoformer/{file_prefix}_plot.png\")\n",
    "    print(f\"‚úÖ Plot saved to ../../outputs/metrics/autoformer/{file_prefix}_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # üíæ Save results\n",
    "    pd.DataFrame({\n",
    "        \"True Values\": true_values,\n",
    "        \"Predictions\": predictions\n",
    "    }).to_csv(f\"../../outputs/metrics/autoformer/{file_prefix}_results.csv\", index=False)\n",
    "    print(f\"‚úÖ Results saved to ../../outputs/metrics/autoformer/{file_prefix}_results.csv\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21b45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä üìà Train Set Forecast vs True\n",
      " - MSE   : 0.000664\n",
      " - MAE   : 0.020301\n",
      " - SMAPE : 8.33%\n",
      "‚úÖ Plot saved to ../../outputs/metrics/autoformer/train_plot.png\n",
      "‚úÖ Results saved to ../../outputs/metrics/autoformer/train_results.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERAT\\AppData\\Local\\Temp\\ipykernel_2660\\437124191.py:44: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f\"../../outputs/metrics/autoformer/{file_prefix}_plot.png\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä üìà Validation Set Forecast vs True\n",
      " - MSE   : 0.000059\n",
      " - MAE   : 0.006783\n",
      " - SMAPE : 5.91%\n",
      "‚úÖ Plot saved to ../../outputs/metrics/autoformer/val_plot.png\n",
      "‚úÖ Results saved to ../../outputs/metrics/autoformer/val_results.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERAT\\AppData\\Local\\Temp\\ipykernel_2660\\437124191.py:44: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f\"../../outputs/metrics/autoformer/{file_prefix}_plot.png\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä üìà Test Set Forecast vs True\n",
      " - MSE   : 0.000043\n",
      " - MAE   : 0.005701\n",
      " - SMAPE : 2.63%\n",
      "‚úÖ Plot saved to ../../outputs/metrics/autoformer/test_plot.png\n",
      "‚úÖ Results saved to ../../outputs/metrics/autoformer/test_results.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERAT\\AppData\\Local\\Temp\\ipykernel_2660\\437124191.py:44: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f\"../../outputs/metrics/autoformer/{file_prefix}_plot.png\")\n"
     ]
    }
   ],
   "source": [
    "# üìà Step 6: Evaluate on All Splits\n",
    "evaluate_model(train_loader, train_df, \"üìà Train Set Forecast vs True\", \"train\")\n",
    "evaluate_model(val_loader, val_df, \"üìà Validation Set Forecast vs True\", \"val\")\n",
    "evaluate_model(test_loader, test_df, \"üìà Test Set Forecast vs True\", \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
